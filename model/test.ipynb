{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "class StoryData(Dataset):\n",
    "    def __init__(self, path, tokenizer):\n",
    "        self.data = open(path, 'r')\n",
    "        \n",
    "        self.dataa = []\n",
    "        count = 0\n",
    "        curr = \"\"\n",
    "        for line in self.data:\n",
    "            if line == \"\": break\n",
    "            if line == \"<|endoftext|>\\n\":\n",
    "                self.dataa.append(curr)\n",
    "                curr = \"\"\n",
    "                count += 1\n",
    "                if count == 100: break\n",
    "                continue\n",
    "            \n",
    "            curr += line.strip() + \" \"\n",
    "\n",
    "        self.X = []      \n",
    "\n",
    "        for i in self.dataa:\n",
    "                self.X.append(i)\n",
    "        \n",
    "        for idx, i in enumerate(self.X):\n",
    "            try:\n",
    "                self.X[idx] = \"<bos> \" + i + \"<bot>: \" + self.X[idx + 1] + \" <eos>\"\n",
    "            except:\n",
    "                break \n",
    "        \n",
    "        self.X = self.X[:1000]\n",
    "        # print(self.X[0])\n",
    "        \n",
    "        self.X_encoded = tokenizer(self.X, max_length=60, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        self.input_ids = self.X_encoded['input_ids']\n",
    "        self.attention_mask = self.X_encoded['attention_mask']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.input_ids[idx], self.attention_mask[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wahid/.conda/envs/bolt2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import tqdm \n",
    "\n",
    "def train(storyData, model, optim):\n",
    "    epochs = 10\n",
    "    for i in tqdm.tqdm(range(epochs)):\n",
    "        for X, a in storyData:\n",
    "            X = X.to(device)\n",
    "            a = a.to(device)\n",
    "            optim.zero_grad()\n",
    "            loss = model(X, attention_mask=a, labels=X).loss\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        torch.save(model.state_dict(), \"model_state.pt\") \n",
    "\n",
    "def infer(inp):\n",
    "    inp = \"<bos> \" + inp + \"<bot>: \"\n",
    "    inp = tokenizer(inp, return_tensors=\"pt\")\n",
    "    X = inp['input_ids'].to(device)\n",
    "    a = inp['attention_mask'].to(device)\n",
    "    output = model.generate(X, attention_mask=a, max_new_tokens=100)\n",
    "    output = tokenizer.decode(output[0])\n",
    "    return output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({\"bos_token\": \"<bos>\",\n",
    "                              \"eos_token\": \"<eos>\"})\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = model.to(device)\n",
    "\n",
    "storyData = StoryData(\"TinyStoriesV2-GPT4-train.txt\", tokenizer)\n",
    "storyData = DataLoader(storyData, batch_size=32)\n",
    "\n",
    "optim = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "train(storyData, model, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: <bos> jack and lily<bot>: ily in the garden. They found a big box that was their toy car. They found a box that was their toy car. It was a box that was open and has no teeth. It was open and has no teeth. It was open and has no teeth. It was open and has no teeth. \"Ahoy, matey!\" said, \"Ahoy, matey!\" \"Ahoy, matey!\" \"Ahoy, matey!\" \"Ahoy, matey!\" \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: <bos> <bot>:  Lily and Ben were playing in the backyard. They had a big box that is their ship and a map that shows where the treasure is. They also have a skull that they found in the garage. Lily and Ben wanted to find it in the garage. They found a skull that they found in the garage. It is open and has no teeth. \"Ahoy, matey!\" Lily asked. \"Ahoy, matey!\" Lily asked, \"Ahoy, matey!\" Lily asked,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: <bos> <bot>:  Lily and Ben were playing in the backyard. They had a big box that is their ship and a map that shows where the treasure is. They also have a skull that they found in the garage. Lily and Ben wanted to find it in the garage. They found a skull that they found in the garage. It is open and has no teeth. \"Ahoy, matey!\" Lily asked. \"Ahoy, matey!\" Lily asked, \"Ahoy, matey!\" Lily asked,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: <bos> <bot>:  Lily and Ben were playing in the backyard. They had a big box that is their ship and a map that shows where the treasure is. They also have a skull that they found in the garage. Lily and Ben wanted to find it in the garage. They found a skull that they found in the garage. It is open and has no teeth. \"Ahoy, matey!\" Lily asked. \"Ahoy, matey!\" Lily asked, \"Ahoy, matey!\" Lily asked,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: <bos> <bot>:  Lily and Ben were playing in the backyard. They had a big box that is their ship and a map that shows where the treasure is. They also have a skull that they found in the garage. Lily and Ben wanted to find it in the garage. They found a skull that they found in the garage. It is open and has no teeth. \"Ahoy, matey!\" Lily asked. \"Ahoy, matey!\" Lily asked, \"Ahoy, matey!\" Lily asked,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: <bos> <bot>:  Lily and Ben were playing in the backyard. They had a big box that is their ship and a map that shows where the treasure is. They also have a skull that they found in the garage. Lily and Ben wanted to find it in the garage. They found a skull that they found in the garage. It is open and has no teeth. \"Ahoy, matey!\" Lily asked. \"Ahoy, matey!\" Lily asked, \"Ahoy, matey!\" Lily asked,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    inp = input(\"You: \")\n",
    "    print(\"Bot:\", infer(inp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
